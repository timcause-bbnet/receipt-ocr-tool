import streamlit as st
from rapidocr_onnxruntime import RapidOCR
from PIL import Image, ImageGrab, ImageEnhance, ImageOps
import pandas as pd
import numpy as np
import re
import cv2
from opencc import OpenCC

cc = OpenCC('s2t')
def to_traditional(text):
    return cc.convert(text)

st.set_page_config(page_title="å…¨èƒ½ OCR (V22 å®Œç¾è­·ç…§ç‰ˆ)", layout="wide", page_icon="ğŸŒ")

# ==========================================
# ğŸŒ è­‰ä»¶è¨­å®š
# ==========================================
DOCUMENT_CONFIG = [
    # 1. å¥ä¿å¡
    {
        "id": "twn_health",
        "label": "ğŸ‡¹ğŸ‡¼ å°ç£å¥ä¿å¡",
        "keywords": ["å…¨æ°‘å¥åº·ä¿éšª", "å¥ä¿"],
        "parser": "twn_health"
    },
    # 2. åœ‹éš›è­·ç…§ (åŒ…å«ä¸­åœ‹ã€ç¾åœ‹ã€æ—¥æœ¬ã€å¾·åœ‹)
    {
        "id": "passport_universal",
        "label": "ğŸŒ åœ‹éš›è­·ç…§",
        "keywords": ["PASSPORT", "P<", "I<", "P[A-Z]<", "REPUBLIC"], 
        "parser": "universal_passport"
    },
    # 3. å°ç£èº«åˆ†è­‰ (åš´æ ¼é™åˆ¶)
    {
        "id": "twn_id_front",
        "label": "ğŸ‡¹ğŸ‡¼ å°ç£èº«åˆ†è­‰ (æ­£é¢)",
        "keywords": ["ä¸­è¯æ°‘åœ‹", "åœ‹æ°‘èº«åˆ†è­‰", "çµ±ä¸€ç·¨è™Ÿ"],
        # æ’é™¤ä»»ä½•å¤–åœ‹é—œéµå­—
        "exclude": ["PASSPORT", "USA", "JAPAN", "GERMANY", "CHINA", "PEOPLE", "REPUBLIC", "DIPLOMATIC"], 
        "parser": "twn_id"
    },
    {
        "id": "twn_id_back",
        "label": "ğŸ‡¹ğŸ‡¼ å°ç£èº«åˆ†è­‰ (èƒŒé¢)",
        "keywords": ["é…å¶", "å½¹åˆ¥", "çˆ¶æ¯", "å‡ºç”Ÿåœ°", "ä½å€"],
        # æ’é™¤è­·ç…§å¸¸è¦‹å­—ï¼Œé¿å…ä¸­åœ‹è­·ç…§(æœ‰å‡ºç”Ÿåœ°/ä½å€)è¢«èª¤åˆ¤
        "exclude": ["PASSPORT", "REPUBLIC", "CHINA", "MINISTRY", "AUTHORITY", "æœ‰æ•ˆæœŸ"], 
        "parser": "twn_id_back"
    }
]

# ==========================================
# ğŸ”§ æ ¸å¿ƒå¼•æ“
# ==========================================
@st.cache_resource
def load_engine():
    return RapidOCR()

engine = load_engine()

def preprocess_red_filter(image):
    if image.mode != 'RGB': image = image.convert('RGB')
    r, g, b = image.split()
    return r.point(lambda p: int(255 * (p / 255) ** 0.6))

def run_ocr(image_pil):
    img_np = np.array(image_pil.convert('RGB'))
    img_cv = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)
    result, _ = engine(img_cv)
    if not result: return "", []
    
    all_text = "\n".join([to_traditional(line[1]) for line in result])
    raw_lines = [to_traditional(line[1]) for line in result]
    return all_text, raw_lines

# ==========================================
# ğŸ§  æ™ºæ…§åˆ†é¡æ ¸å¿ƒ
# ==========================================
def detect_document_type(clean_text):
    # 1. çµ•å°å„ªå…ˆï¼šMRZ ç‰¹å¾µ
    # P<... æˆ– I<... æˆ– PDCHN... (ä¸­åœ‹å¤–äº¤è­·ç…§)
    if re.search(r'[PI]<[A-Z]{3}', clean_text) or "PDCHN" in clean_text or "PASSPORT" in clean_text:
        return next((d for d in DOCUMENT_CONFIG if d["id"] == "passport_universal"), None)

    best_match = None
    max_score = 0
    
    for doc in DOCUMENT_CONFIG:
        if "exclude" in doc:
            if any(ex in clean_text for ex in doc["exclude"]):
                continue
        
        score = 0
        for kw in doc["keywords"]:
            if kw in clean_text:
                score += 1
        
        if score > max_score:
            max_score = score
            best_match = doc
            
    # Fallback: åªæœ‰åœ¨å®Œå…¨æ²’æœ‰å¤–åœ‹é—œéµå­—æ™‚ï¼Œæ‰å…è¨±çŒœå°ç£ ID
    if not best_match and re.search(r'[A-Z][12]\d{8}', clean_text):
        if not any(k in clean_text for k in ["USA", "CHINA", "JAPAN", "REPUBLIC", "PEOPLE"]):
            return next((d for d in DOCUMENT_CONFIG if d["id"] == "twn_id_front"), None)
    
    return best_match

# ==========================================
# ğŸ“ è§£æå™¨ï¼šMRZ å„ªå…ˆ + é€—è™Ÿå›æ­¸
# ==========================================

def parse_mrz(clean_text):
    """
    å¼·å¤§çš„ MRZ è§£æå™¨ (æ”¯æ´ TD3/TD1/å¤–äº¤è­·ç…§)
    """
    mrz_data = {}
    lines = clean_text.split('\n')
    clean_lines = [l.replace(" ", "").upper() for l in lines]
    
    for i, l in enumerate(clean_lines):
        # æ¨¡å¼ 1: æ¨™æº–è­·ç…§ (P<TWN, P<JPN, P<D, PDCHN)
        if len(l) > 30 and (l.startswith("P") or l.startswith("V") or l.startswith("I")):
            # æŠ“åå­—: ä½æ–¼ç¬¬ä¸€å€‹åœ‹ç¢¼ä¹‹å¾Œï¼Œç›´åˆ°ä¸‹ä¸€å€‹æ•¸å­—æˆ–è¡Œå°¾
            # æ ¼å¼é€šå¸¸æ˜¯: P<CCCSURNAME<<GIVEN<NAME<<<<
            if "<<" in l:
                try:
                    # åˆ†å‰²å‡ºå„å€‹å€å¡Š
                    parts = l.split("<")
                    # éæ¿¾æ‰åœ‹ç¢¼ (å‰3-5ç¢¼é€šå¸¸æ˜¯åœ‹ç¢¼) å’Œ P
                    # ç°¡å–®ç­–ç•¥ï¼šå–é•·åº¦å¤§æ–¼ 1 ä¸”ä¸æ˜¯ç´”æ•¸å­—çš„å€å¡Š
                    valid_parts = []
                    for p in parts:
                        if len(p) >= 2 and not any(c.isdigit() for c in p):
                            # æ’é™¤å¸¸è¦‹åœ‹ç¢¼
                            if p not in ["TWN", "CHN", "JPN", "USA", "D", "DEU", "FRA"]:
                                valid_parts.append(p)
                    
                    if valid_parts:
                        # é€™æ˜¯ Surname, Given Name
                        mrz_data['eng_name'] = ", ".join(valid_parts)
                except: pass

            # æŠ“è™Ÿç¢¼: é€šå¸¸åœ¨ä¸‹ä¸€è¡Œ
            if i+1 < len(clean_lines):
                l2 = clean_lines[i+1]
                # è™Ÿç¢¼ç‰¹å¾µ: å‰9ç¢¼æ˜¯è‹±æ•¸æ··åˆ (ä¸­åœ‹å¤–äº¤è­·ç…§æ˜¯ DE...)
                pass_no = re.search(r'[A-Z0-9]{7,9}', l2)
                if pass_no: 
                    mrz_data['passport_no'] = pass_no.group(0)

        # æ¨¡å¼ 2: ç¾åœ‹å¡ (I<USA)
        if l.startswith("I<") or l.startswith("C<"):
            # Line 1: è™Ÿç¢¼åœ¨åœ‹ç¢¼å¾Œ
            pass_no = re.search(r'(?<=<)[A-Z0-9]{9}', l)
            if not pass_no: pass_no = re.search(r'[A-Z0-9]{9}', l[2:])
            if pass_no: mrz_data['passport_no'] = pass_no.group(0)
            
            # Line 3: åå­— (å¾€ä¸‹æ‰¾)
            for j in range(i+1, min(i+4, len(clean_lines))):
                if "<<" in clean_lines[j]:
                    parts = clean_lines[j].split("<<")
                    names = [p.replace("<", " ") for p in parts if p]
                    mrz_data['eng_name'] = ", ".join(names)
                    break

    return mrz_data

def parse_universal_passport(clean_text, raw_lines):
    data = {}
    
    # 1. MRZ è§£æ (æœ€æº–ç¢ºï¼Œå„ªå…ˆä½¿ç”¨)
    data.update(parse_mrz(clean_text))
    
    # 2. è¦–è¦ºè£œå¼· (å¦‚æœ MRZ æ²’æŠ“åˆ°)
    
    # [è­·ç…§è™Ÿç¢¼]
    if "passport_no" not in data:
        # æ’é™¤æ¨™é¡Œ (Passport No)
        cands = re.findall(r'[A-Z0-9]{7,9}', clean_text)
        for c in cands:
            # å¿…é ˆåŒ…å«æ•¸å­— (é¿å…æŠ“åˆ°å–®ç´”è‹±æ–‡å–®å­—) ä¸”ä¸æ˜¯é—œéµå­—
            if any(char.isdigit() for char in c) and "PASS" not in c and "CODE" not in c:
                data['passport_no'] = c
                break

    # [è‹±æ–‡å§“å] - å›æ­¸é€—è™Ÿé‚è¼¯ (æœ€ç©©)
    if "eng_name" not in data:
        for line in raw_lines:
            # æ¢ä»¶ï¼šå…¨å¤§å¯« + åŒ…å«é€—è™Ÿ + é•·åº¦å¤ 
            if re.search(r'[A-Z]', line) and "," in line and len(line) > 5:
                # æ’é™¤é»‘åå–®
                line_upper = line.upper()
                blacklist = ["NAME", "SURNAME", "GIVEN", "MINISTRY", "REPUBLIC", "BIRTH", "PASSPORT", "SEX", "AUTHORITY", "DATE", "NATIONALITY"]
                if any(bad in line_upper for bad in blacklist): continue
                if re.search(r'\d', line): continue # ä¸èƒ½æœ‰æ•¸å­—
                
                # æ‰¾åˆ° LIN, MEI-HUA
                data['eng_name'] = line
                break
                
        # å‚™ç”¨ï¼šå¦‚æœæ²’é€—è™Ÿ (åƒå¾·åœ‹è­·ç…§æœ‰æ™‚åˆ†å…©è¡Œ)
        if "eng_name" not in data:
             # æ‰¾å…¨å¤§å¯«è¡Œï¼Œæ’é™¤æ¨™é¡Œ
             for line in raw_lines:
                 if re.match(r'^[A-Z\s\-]+$', line) and len(line) > 4:
                     if not any(k in line for k in ["NAME", "REP", "MIN", "PASS", "TYPE"]):
                         data['eng_name'] = line
                         break

    # 3. å°ç£èº«åˆ†è­‰å­—è™Ÿ (ç‰¹ä¾‹)
    if "TAIWAN" in clean_text:
        id_match = re.search(r'[A-Z][12]\d{8}', clean_text)
        data['id_no'] = id_match.group(0) if id_match else ""
        
    return data

def parse_twn_id(clean_text, raw_lines, img_orig):
    data = {}
    id_match = re.search(r'[A-Z][12]\d{8}', clean_text)
    data['id_no'] = id_match.group(0) if id_match else ""
    
    img_filter = preprocess_red_filter(img_orig)
    _, lines_filter = run_ocr(img_filter)
    
    def find_name(lines):
        for i, line in enumerate(lines):
            if "å§“å" in line:
                val = line.replace("å§“å", "").strip()
                if len(val) > 1: return val
                if i+1 < len(lines): return lines[i+1]
        return ""
    
    name = find_name(lines_filter)
    if not name: name = find_name(raw_lines)
    data['name'] = name.replace("æ¨£æœ¬", "").replace("æ¨£", "").replace("æœ¬", "").strip()
    
    dob_match = re.search(r'æ°‘åœ‹\s*(\d{2,3})\s*å¹´\s*(\d{1,2})\s*æœˆ\s*(\d{1,2})\s*æ—¥', clean_text)
    data['dob'] = dob_match.group(0) if dob_match else ""
    return data

def parse_twn_id_back(clean_text, raw_lines):
    data = {}
    addr = "".join([l for l in raw_lines if any(k in l for k in ["ç¸£", "å¸‚", "å€", "è·¯", "è¡—"])])
    data['address'] = addr.replace("ä½å€", "")
    return data

def parse_twn_health(clean_text, raw_lines):
    data = {}
    for line in raw_lines:
        c_line = re.sub(r'[^\u4e00-\u9fa5]', '', line)
        if "å…¨æ°‘" in c_line or "ä¿éšª" in c_line: continue
        if 2 <= len(c_line) <= 4:
            data['name'] = c_line
            break
    id_match = re.search(r'[A-Z][12]\d{8}', clean_text)
    data['id_no'] = id_match.group(0) if id_match else ""
    card_match = re.search(r'\d{12}', clean_text)
    data['card_no'] = card_match.group(0) if card_match else ""
    return data

PARSERS = {
    "twn_id": parse_twn_id,
    "twn_id_back": parse_twn_id_back,
    "twn_health": parse_twn_health,
    "universal_passport": parse_universal_passport
}

# ==========================================
# æ‚ éŠå¡ (ä¿æŒä¸è®Š)
# ==========================================
def parse_easycard_func(text_lines):
    data = []
    for line in text_lines:
        line = line.strip()
        date_match = re.search(r'(\d{4}[-/]\d{2}[-/]\d{2})', line)
        time_match = re.search(r'(\d{2}:\d{2}:\d{2})', line)
        amount_match = re.search(r'[-]?\d+', line[::-1]) 
        if date_match and time_match:
            full_date = date_match.group(1).replace("/", "-")
            time_part = time_match.group(1)
            amount = 0
            if amount_match: amount = amount_match.group(0)[::-1]
            loc_raw = line
            for useless in [full_date, full_date.replace("-", "/"), time_part, str(amount), "æ‰£æ¬¾", "äº¤æ˜“", "é€£ç·š"]:
                loc_raw = loc_raw.replace(useless, "")
            loc_raw = loc_raw.strip()
            if "åŠ å€¼" in loc_raw: continue
            transport_type = "æ·é‹"
            if "å°éµ" in loc_raw: transport_type = "å°éµ"
            elif "å®¢é‹" in loc_raw: transport_type = "å®¢é‹"
            elif "é«˜éµ" in loc_raw: transport_type = "é«˜éµ"
            elif "è·¯" in loc_raw or "è»Š" in loc_raw: transport_type = "å…¬è»Š"
            data.append({
                "é¸å–": True,
                "å®Œæ•´æ—¥æœŸ": f"{full_date} {time_part}",
                "çŸ­æ—¥æœŸ": full_date[5:].replace("-", "/"),
                "äº¤é€š": transport_type,
                "è¨–é»": loc_raw,
                "é‡‘é¡": str(amount).replace("-", "")
            })
    return data

# ==========================================
# ä»‹é¢
# ==========================================
st.sidebar.title("ğŸŒ è¬åœ‹ OCR")
app_mode = st.sidebar.radio("åŠŸèƒ½é¸å–®", ["ğŸ’³ æ‚ éŠå¡å ±è¡¨", "ğŸªª è­‰ä»¶è¾¨è­˜ (è‡ªå‹•å¤šåœ‹)"])

if app_mode == "ğŸ’³ æ‚ éŠå¡å ±è¡¨":
    st.title("ğŸ’³ æ‚ éŠå¡å ±è¡¨")
    uploaded_file = st.file_uploader("ä¸Šå‚³æˆªåœ–", type=['png', 'jpg', 'jpeg'])
    if uploaded_file:
        image = Image.open(uploaded_file)
        st.image(image, width=500)
        if st.button("ğŸš€ è¾¨è­˜"):
            _, lines = run_ocr(image)
            df = pd.DataFrame(parse_easycard_func(lines))
            if not df.empty: st.data_editor(df, use_container_width=True)
            else: st.error("ç„¡è³‡æ–™")

else:
    st.title("ğŸªª æ™ºæ…§è­‰ä»¶è¾¨è­˜ (V22 å®Œç¾ç‰ˆ)")
    supported = ", ".join([d['label'] for d in DOCUMENT_CONFIG])
    st.caption(f"ç›®å‰æ”¯æ´ï¼š{supported}")
    
    uploaded_file = st.file_uploader("ä¸Šå‚³è­‰ä»¶", type=['png', 'jpg', 'jpeg'])
    
    if uploaded_file:
        image = Image.open(uploaded_file)
        st.image(image, caption="å·²ä¸Šå‚³", width=400)
        
        if st.button("ğŸš€ é–‹å§‹è¾¨è­˜"):
            with st.spinner('AI æ­£åœ¨åˆ†æ...'):
                full_text, lines = run_ocr(image)
                clean_text = re.sub(r'[\s\.\-\_]+', '', full_text).upper().replace("O", "0").replace("I", "1").replace("L", "1")
                
                doc_conf = detect_document_type(clean_text)
                
                if not doc_conf:
                    st.error("âš ï¸ ç„¡æ³•è­˜åˆ¥è­‰ä»¶é¡å‹ï¼Œè«‹ç¢ºèªç…§ç‰‡æ¸…æ™°åº¦ã€‚")
                    with st.expander("é™¤éŒ¯"): st.text(full_text)
                else:
                    st.success(f"âœ… è­˜åˆ¥æˆåŠŸï¼š{doc_conf['label']}")
                    parser_name = doc_conf['parser']
                    parser_func = PARSERS[parser_name]
                    
                    if parser_name == "twn_id":
                        data = parser_func(clean_text, lines, image)
                    else:
                        data = parser_func(clean_text, lines)
                    
                    st.subheader("ğŸ“ è¾¨è­˜çµæœ")
                    with st.form("res"):
                        c1, c2 = st.columns(2)
                        
                        if "name" in data: c1.text_input("å§“å (ä¸­æ–‡)", data['name'])
                        if "eng_name" in data: c1.text_input("å§“å (è‹±æ–‡)", data['eng_name'])
                        
                        if "id_no" in data: c2.text_input("èº«åˆ†è­‰/å…¬æ°‘è™Ÿ", data['id_no'])
                        if "passport_no" in data: c2.text_input("è­·ç…§è™Ÿç¢¼", data['passport_no'])
                        if "card_no" in data: c2.text_input("å¥ä¿å¡è™Ÿ", data['card_no'])
                        
                        if "dob" in data: st.text_input("å‡ºç”Ÿæ—¥æœŸ", data['dob'])
                        if "address" in data: st.text_input("ä½å€", data['address'])
                        
                        if "father" in data: 
                            c1.text_input("çˆ¶è¦ª", data['father'])
                            c2.text_input("æ¯è¦ª", data['mother'])
                        if "spouse" in data: st.text_input("é…å¶", data['spouse'])
                        
                        st.form_submit_button("ğŸ’¾ å­˜æª”")