import streamlit as st
from rapidocr_onnxruntime import RapidOCR
from PIL import Image, ImageGrab, ImageEnhance, ImageOps
import pandas as pd
import numpy as np
import re
import cv2
from opencc import OpenCC

cc = OpenCC('s2t')
def to_traditional(text):
    return cc.convert(text)

st.set_page_config(page_title="å…¨èƒ½ OCR (V23 è¦–è¦ºæš´åŠ›ç‰ˆ)", layout="wide", page_icon="ğŸŒ")

# ==========================================
# ğŸŒ è­‰ä»¶è¨­å®š (é‚è¼¯å„ªåŒ–ï¼šè­·ç…§å„ªå…ˆæ¬Šæœ€é«˜)
# ==========================================
DOCUMENT_CONFIG = [
    # 1. å¥ä¿å¡
    {
        "id": "twn_health",
        "label": "ğŸ‡¹ğŸ‡¼ å°ç£å¥ä¿å¡",
        "keywords": ["å…¨æ°‘å¥åº·ä¿éšª", "å¥ä¿"],
        "parser": "twn_health"
    },
    # 2. åœ‹éš›è­·ç…§ (æ¬Šé‡æœ€é«˜ï¼ŒåŒ…å«æ‰€æœ‰åœ‹å®¶)
    {
        "id": "passport_universal",
        "label": "ğŸŒ åœ‹éš›è­·ç…§",
        "keywords": ["PASSPORT", "P<", "I<", "REPUBLIC", "JAPAN", "USA", "DEUTSCHLAND", "CHINA"], 
        "parser": "universal_passport"
    },
    # 3. å°ç£èº«åˆ†è­‰ (æ’é™¤å¤–åœ‹é—œéµå­—ï¼Œé˜²æ­¢èª¤åˆ¤)
    {
        "id": "twn_id_front",
        "label": "ğŸ‡¹ğŸ‡¼ å°ç£èº«åˆ†è­‰ (æ­£é¢)",
        "keywords": ["ä¸­è¯æ°‘åœ‹", "åœ‹æ°‘èº«åˆ†è­‰", "çµ±ä¸€ç·¨è™Ÿ"],
        "exclude": ["PASSPORT", "USA", "JAPAN", "GERMANY", "DEUTSCHLAND", "å…±å’Œåœ‹", "CHINA", "PEOPLE"], 
        "parser": "twn_id"
    },
    {
        "id": "twn_id_back",
        "label": "ğŸ‡¹ğŸ‡¼ å°ç£èº«åˆ†è­‰ (èƒŒé¢)",
        "keywords": ["é…å¶", "å½¹åˆ¥", "çˆ¶æ¯", "å‡ºç”Ÿåœ°", "ä½å€"],
        "exclude": ["PASSPORT", "REPUBLIC", "CHINA", "MINISTRY"], 
        "parser": "twn_id_back"
    }
]

# ==========================================
# ğŸ”§ æ ¸å¿ƒå¼•æ“
# ==========================================
@st.cache_resource
def load_engine():
    return RapidOCR()

engine = load_engine()

def preprocess_red_filter(image):
    if image.mode != 'RGB': image = image.convert('RGB')
    r, g, b = image.split()
    return r.point(lambda p: int(255 * (p / 255) ** 0.6))

def run_ocr(image_pil):
    img_np = np.array(image_pil.convert('RGB'))
    img_cv = cv2.cvtColor(img_np, cv2.COLOR_RGB2BGR)
    result, _ = engine(img_cv)
    if not result: return "", []
    
    all_text = "\n".join([to_traditional(line[1]) for line in result])
    raw_lines = [to_traditional(line[1]) for line in result]
    return all_text, raw_lines

# ==========================================
# ğŸ§  æ™ºæ…§åˆ†é¡æ ¸å¿ƒ
# ==========================================
def detect_document_type(clean_text):
    # 1. çµ•å°å„ªå…ˆï¼šåªè¦æœ‰ PASSPORT æˆ– å…±å’Œåœ‹(é‡å°ä¸­åœ‹è­·ç…§)ï¼Œç›´æ¥é–å®šè­·ç…§
    if "PASSPORT" in clean_text or "REPUBLIC" in clean_text or "P<" in clean_text:
        # å†æ¬¡ç¢ºèªä¸æ˜¯å°ç£èº«åˆ†è­‰ (å°ç£èº«åˆ†è­‰é›–ç„¶æœ‰ REPUBLIC OF CHINAï¼Œä½†é€šå¸¸æ¯”è¼ƒå°)
        # å¦‚æœåŒæ™‚æœ‰ "èº«åˆ†è­‰" å­—æ¨£ï¼Œæ‰è½‰å›å»ï¼Œå¦å‰‡é è¨­è­·ç…§
        if "èº«åˆ†è­‰" not in clean_text:
            return next((d for d in DOCUMENT_CONFIG if d["id"] == "passport_universal"), None)

    best_match = None
    max_score = 0
    
    for doc in DOCUMENT_CONFIG:
        if "exclude" in doc:
            if any(ex in clean_text for ex in doc["exclude"]):
                continue
        
        score = 0
        for kw in doc["keywords"]:
            if kw in clean_text:
                score += 1
        
        if score > max_score:
            max_score = score
            best_match = doc
            
    # Fallback: åªæœ‰å®Œå…¨æ²’ç‰¹å¾µæ™‚ï¼Œæ‰å…è¨±çŒœå°ç£ ID
    if not best_match and re.search(r'[A-Z][12]\d{8}', clean_text):
        if not any(k in clean_text for k in ["USA", "CHINA", "JAPAN", "GERMANY"]):
            return next((d for d in DOCUMENT_CONFIG if d["id"] == "twn_id_front"), None)
    
    return best_match

# ==========================================
# ğŸ“ è§£æå™¨ï¼šè¦–è¦ºæš´åŠ›æŠ“å– (Visual Extraction)
# ==========================================

def parse_universal_passport(clean_text, raw_lines):
    data = {}
    
    # === 1. è­·ç…§è™Ÿç¢¼ (é‡å°å³ä¸Šè§’ç´…æ¡†è™•æš´åŠ›æŠ“å–) ===
    # æˆ‘å€‘ä¸ä¾è³´ "Passport No" æ¨™ç±¤ï¼Œç›´æ¥æ‰¾ç¬¦åˆæ ¼å¼çš„å­—ä¸²
    
    # å€™é¸æ¸…å–®ï¼šæŠ“å‡ºæ‰€æœ‰å¯èƒ½çš„è™Ÿç¢¼
    candidates = []
    
    # æ ¼å¼ A: ç¾åœ‹å¡/å¾·åœ‹ (Cé–‹é ­ + 8-9ç¢¼)
    candidates += re.findall(r'[C][0-9A-Z]{8,9}', clean_text)
    # æ ¼å¼ B: æ—¥æœ¬ (é›™å­—æ¯ + 7ç¢¼æ•¸å­—)
    candidates += re.findall(r'[A-Z]{2}\d{7}', clean_text)
    # æ ¼å¼ C: ä¸­åœ‹å¤–äº¤ (DE + æ•¸å­—) æˆ– ä¸€èˆ¬ (E/G + æ•¸å­—)
    candidates += re.findall(r'D[E]\d{7}', clean_text)
    candidates += re.findall(r'[EG]\d{8}', clean_text)
    # æ ¼å¼ D: å°ç£/å…¶ä»– (9ç¢¼æ•¸å­—)
    candidates += re.findall(r'\d{9}', clean_text)
    # æ ¼å¼ E: å¾·åœ‹/é€šç”¨ (9ç¢¼è‹±æ•¸æ··åˆ)
    candidates += re.findall(r'[C-Z0-9]{9}', clean_text)

    # éæ¿¾å€™é¸åå–®
    for cand in candidates:
        # æ’é™¤é—œéµå­—
        if any(x in cand for x in ["PASS", "PORT", "REP", "CHN", "USA", "TWN", "JPN", "CODE", "TYPE"]):
            continue
        # å¾·åœ‹è­·ç…§è™Ÿç¢¼ç‰¹å¾µ (ä¸æœƒæœ‰æ¯éŸ³ï¼Œé¿å…çµ„æˆå–®å­—)
        # é€™è£¡ç°¡å–®åˆ¤æ–·ï¼šå¦‚æœé•·åº¦æ˜¯ 9 ä¸”åŒ…å«æ•¸å­—ï¼Œå„ªå…ˆåº¦é«˜
        data['passport_no'] = cand
        break # æŠ“åˆ°ç¬¬ä¸€å€‹ç¬¦åˆçš„å°±åœ (é€šå¸¸å³ä¸Šè§’æœƒå…ˆè¢« OCR è®€åˆ°)

    # === 2. è‹±æ–‡å§“å (å›æ­¸é€—è™Ÿé‚è¼¯) ===
    # é€™æ˜¯æ‚¨è¦ºå¾—æœ€æº–çš„é‚è¼¯
    for line in raw_lines:
        # æ¢ä»¶ï¼šå…¨å¤§å¯« + é€—è™Ÿ (LIN, MEI-HUA)
        if re.search(r'[A-Z]', line) and "," in line:
            # æ’é™¤é»‘åå–® (æ¨™é¡Œ)
            line_upper = line.upper()
            blacklist = ["NAME", "SURNAME", "GIVEN", "MINISTRY", "REPUBLIC", "BIRTH", "PASSPORT", "SEX", "AUTHORITY", "DATE", "NATIONALITY"]
            if any(bad in line_upper for bad in blacklist): continue
            if re.search(r'\d', line): continue 
            
            # æ‰¾åˆ°åå­—
            data['eng_name'] = line
            break
    
    # å¦‚æœæ²’é€—è™Ÿ (åƒå¾·åœ‹è­·ç…§å¯èƒ½æ˜¯åˆ†å…©è¡Œ)ï¼Œå˜—è©¦æ‰¾ Name ä¸‹é¢çš„å­—
    if "eng_name" not in data:
        for i, line in enumerate(raw_lines):
            if "NAME" in line.upper() or "SURNAME" in line.upper():
                if i + 1 < len(raw_lines):
                    potential_name = raw_lines[i+1]
                    # ç°¡å–®é©—è­‰ï¼šå…¨å¤§å¯«ä¸”ç„¡æ•¸å­—
                    if re.match(r'^[A-Z\s]+$', potential_name) and len(potential_name) > 3:
                        data['eng_name'] = potential_name
                        break

    # === 3. å°ç£èº«åˆ†è­‰å­—è™Ÿ (ç‰¹ä¾‹) ===
    if "TAIWAN" in clean_text:
        id_match = re.search(r'[A-Z][12]\d{8}', clean_text)
        data['id_no'] = id_match.group(0) if id_match else ""
        
    return data

# === ä»¥ä¸‹å°ç£è­‰ä»¶é‚è¼¯ä¿æŒä¸å‹• ===

def parse_twn_id(clean_text, raw_lines, img_orig):
    data = {}
    id_match = re.search(r'[A-Z][12]\d{8}', clean_text)
    data['id_no'] = id_match.group(0) if id_match else ""
    
    img_filter = preprocess_red_filter(img_orig)
    _, lines_filter = run_ocr(img_filter)
    
    def find_name(lines):
        for i, line in enumerate(lines):
            if "å§“å" in line:
                val = line.replace("å§“å", "").strip()
                if len(val) > 1: return val
                if i+1 < len(lines): return lines[i+1]
        return ""
    
    name = find_name(lines_filter)
    if not name: name = find_name(raw_lines)
    data['name'] = name.replace("æ¨£æœ¬", "").replace("æ¨£", "").replace("æœ¬", "").strip()
    
    dob_match = re.search(r'æ°‘åœ‹\s*(\d{2,3})\s*å¹´\s*(\d{1,2})\s*æœˆ\s*(\d{1,2})\s*æ—¥', clean_text)
    data['dob'] = dob_match.group(0) if dob_match else ""
    return data

def parse_twn_id_back(clean_text, raw_lines):
    data = {}
    addr = "".join([l for l in raw_lines if any(k in l for k in ["ç¸£", "å¸‚", "å€", "è·¯", "è¡—"])])
    data['address'] = addr.replace("ä½å€", "")
    return data

def parse_twn_health(clean_text, raw_lines):
    data = {}
    for line in raw_lines:
        c_line = re.sub(r'[^\u4e00-\u9fa5]', '', line)
        if "å…¨æ°‘" in c_line or "ä¿éšª" in c_line: continue
        if 2 <= len(c_line) <= 4:
            data['name'] = c_line
            break
    id_match = re.search(r'[A-Z][12]\d{8}', clean_text)
    data['id_no'] = id_match.group(0) if id_match else ""
    card_match = re.search(r'\d{12}', clean_text)
    data['card_no'] = card_match.group(0) if card_match else ""
    return data

PARSERS = {
    "twn_id": parse_twn_id,
    "twn_id_back": parse_twn_id_back,
    "twn_health": parse_twn_health,
    "universal_passport": parse_universal_passport
}

# ==========================================
# æ‚ éŠå¡ (ä¿æŒä¸è®Š)
# ==========================================
def parse_easycard_func(text_lines):
    data = []
    for line in text_lines:
        line = line.strip()
        date_match = re.search(r'(\d{4}[-/]\d{2}[-/]\d{2})', line)
        time_match = re.search(r'(\d{2}:\d{2}:\d{2})', line)
        amount_match = re.search(r'[-]?\d+', line[::-1]) 
        if date_match and time_match:
            full_date = date_match.group(1).replace("/", "-")
            time_part = time_match.group(1)
            amount = 0
            if amount_match: amount = amount_match.group(0)[::-1]
            loc_raw = line
            for useless in [full_date, full_date.replace("-", "/"), time_part, str(amount), "æ‰£æ¬¾", "äº¤æ˜“", "é€£ç·š"]:
                loc_raw = loc_raw.replace(useless, "")
            loc_raw = loc_raw.strip()
            if "åŠ å€¼" in loc_raw: continue
            transport_type = "æ·é‹"
            if "å°éµ" in loc_raw: transport_type = "å°éµ"
            elif "å®¢é‹" in loc_raw: transport_type = "å®¢é‹"
            elif "é«˜éµ" in loc_raw: transport_type = "é«˜éµ"
            elif "è·¯" in loc_raw or "è»Š" in loc_raw: transport_type = "å…¬è»Š"
            data.append({
                "é¸å–": True,
                "å®Œæ•´æ—¥æœŸ": f"{full_date} {time_part}",
                "çŸ­æ—¥æœŸ": full_date[5:].replace("-", "/"),
                "äº¤é€š": transport_type,
                "è¨–é»": loc_raw,
                "é‡‘é¡": str(amount).replace("-", "")
            })
    return data

# ==========================================
# ä»‹é¢
# ==========================================
st.sidebar.title("ğŸŒ è¬åœ‹ OCR")
app_mode = st.sidebar.radio("åŠŸèƒ½é¸å–®", ["ğŸ’³ æ‚ éŠå¡å ±è¡¨", "ğŸªª è­‰ä»¶è¾¨è­˜ (è‡ªå‹•å¤šåœ‹)"])

if app_mode == "ğŸ’³ æ‚ éŠå¡å ±è¡¨":
    st.title("ğŸ’³ æ‚ éŠå¡å ±è¡¨")
    uploaded_file = st.file_uploader("ä¸Šå‚³æˆªåœ–", type=['png', 'jpg', 'jpeg'])
    if uploaded_file:
        image = Image.open(uploaded_file)
        st.image(image, width=500)
        if st.button("ğŸš€ è¾¨è­˜"):
            _, lines = run_ocr(image)
            df = pd.DataFrame(parse_easycard_func(lines))
            if not df.empty: st.data_editor(df, use_container_width=True)
            else: st.error("ç„¡è³‡æ–™")

else:
    st.title("ğŸªª æ™ºæ…§è­‰ä»¶è¾¨è­˜ (V23 è¦–è¦ºæš´åŠ›ç‰ˆ)")
    supported = ", ".join([d['label'] for d in DOCUMENT_CONFIG])
    st.caption(f"ç›®å‰æ”¯æ´ï¼š{supported}")
    
    uploaded_file = st.file_uploader("ä¸Šå‚³è­‰ä»¶", type=['png', 'jpg', 'jpeg'])
    
    if uploaded_file:
        image = Image.open(uploaded_file)
        st.image(image, caption="å·²ä¸Šå‚³", width=400)
        
        if st.button("ğŸš€ é–‹å§‹è¾¨è­˜"):
            with st.spinner('AI æ­£åœ¨åˆ†æç‰¹å¾µ...'):
                full_text, lines = run_ocr(image)
                clean_text = re.sub(r'[\s\.\-\_]+', '', full_text).upper().replace("O", "0").replace("I", "1").replace("L", "1")
                
                doc_conf = detect_document_type(clean_text)
                
                if not doc_conf:
                    st.error("âš ï¸ ç„¡æ³•è­˜åˆ¥è­‰ä»¶é¡å‹ï¼Œè«‹ç¢ºèªç…§ç‰‡æ¸…æ™°åº¦ã€‚")
                    with st.expander("é™¤éŒ¯"): st.text(full_text)
                else:
                    st.success(f"âœ… è­˜åˆ¥æˆåŠŸï¼š{doc_conf['label']}")
                    parser_name = doc_conf['parser']
                    parser_func = PARSERS[parser_name]
                    
                    if parser_name == "twn_id":
                        data = parser_func(clean_text, lines, image)
                    else:
                        data = parser_func(clean_text, lines)
                    
                    st.subheader("ğŸ“ è¾¨è­˜çµæœ")
                    with st.form("res"):
                        c1, c2 = st.columns(2)
                        
                        if "name" in data: c1.text_input("å§“å (ä¸­æ–‡)", data['name'])
                        if "eng_name" in data: c1.text_input("å§“å (è‹±æ–‡)", data['eng_name'])
                        
                        if "id_no" in data: c2.text_input("èº«åˆ†è­‰/å…¬æ°‘è™Ÿ", data['id_no'])
                        if "passport_no" in data: c2.text_input("è­·ç…§è™Ÿç¢¼", data['passport_no'])
                        if "card_no" in data: c2.text_input("å¥ä¿å¡è™Ÿ", data['card_no'])
                        
                        if "dob" in data: st.text_input("å‡ºç”Ÿæ—¥æœŸ", data['dob'])
                        if "address" in data: st.text_input("ä½å€", data['address'])
                        
                        if "father" in data: 
                            c1.text_input("çˆ¶è¦ª", data['father'])
                            c2.text_input("æ¯è¦ª", data['mother'])
                        if "spouse" in data: st.text_input("é…å¶", data['spouse'])
                        
                        st.form_submit_button("ğŸ’¾ å­˜æª”")